{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ONLINEREVIEWCLASSIFICATION",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-unZVnf_znF"
      },
      "source": [
        "# **MIS 515 HOMEWORK 5/6: ONLINE REVIEW CLASSIFICATION**\n",
        "Your assignment is to create atoolthat trains several machine learning models to perform the task of classifying online reviews. Some of these online reviews refer to hazardous products, so these machine learning models will help to identify the most serious product complaints.\n",
        "\n",
        "The dataset is available at https://dgoldberg.sdsu.edu/515/appliance_reviews.json and contains approximately 1,000 reviews, approximately half of which refer to safety hazards. The data is formatted as a JSON array.\n",
        "\n",
        "The purpose of the machine learning models is to predict the “Safety hazard” field, which is already formatted as a 0 or 1. A value of 1 indicates that the review refers to a safety hazard; a value of 0 indicates that the review does not refer to a safety hazard. However, to transform the reviews into a format usable by the machine learning models, perform the following steps:\n",
        "\n",
        "- Throughout the problem, ensure that you handle case-sensitivity (for example, by converting all reviews to lowercase).\n",
        "- Next, createa list of all the *unique* words in the dataset. For example, the word “plastic” occurs multiple times throughout the dataset. However, this is only one unique word, so only append it to your list one time.\n",
        "- The dataset consists of many words, so the next step is to narrow down which words are relevant to the classification problem (otherwise, the machine learning models may have too many variables to considerand run very slowly). To do so, generate a “relevance score” for each word by first computing totals of A, B, C, and D\n",
        "- Next, create a 2D list to train the machine learning models based on the relevant words from the previous step. If a review contains a given word, then use a value of 1, and if not, then use a value of 0. For example, suppose that the relevant words are [“dangerous”, “hazard”, “broken”] and that you are considering the review “the product was dangerous and scary.” This review should be treated as [1, 0, 0] because it contains the word “dangerous” but does not contain the words “hazard” or “broken.”\n",
        "- Finally, train decision tree, k-nearest neighbors, and neural network machine learning models. You may choose your owntraining-test split. Report the accuracy values from all three machine learning models and save a joblib file from the most accurate model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4DyqOqnMqSd"
      },
      "source": [
        "#Calculate Relevance Score Helper Function\n",
        "def relevanceScore(a,b,c,d):\n",
        "  radicand1 = a + b + c + d\n",
        "  radicand2 = (a + b) * (c + d)\n",
        "  top = math.sqrt(radicand1) * ((a*d) - (c*b))\n",
        "  bottom = math.sqrt(radicand2)\n",
        "  if bottom == 0:\n",
        "    return 0\n",
        "  else:\n",
        "    return top / bottom\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kil0Ule5gVBW"
      },
      "source": [
        "import json,joblib,google.colab.files, requests, numpy as np, math, sklearn.neighbors, sklearn.neural_network, sklearn.metrics, sklearn.model_selection, sklearn.tree\n",
        "from textblob import TextBlob\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "response = requests.get('https://dgoldberg.sdsu.edu/515/appliance_reviews.json')\n",
        "\n",
        "data = json.loads(response.text)   \n",
        "  \n",
        "if response:\n",
        "  print(json.dumps(data, indent=4))\n",
        "else:\n",
        "  print('Sorry, could not connnect.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wsKJnwMyeI9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaf5137b-542b-49b0-a4b0-c9acc2de3de1"
      },
      "source": [
        "#Separate data\n",
        "print('Loading data...')\n",
        "reviews = []\n",
        "stars = []\n",
        "hazard = []\n",
        "x = []\n",
        "y = []\n",
        "for i in range(len(data)):\n",
        "  reviews.append(data[i]['Review'].lower())\n",
        "  stars.append(data[i]['Stars'])\n",
        "  hazard.append(data[i]['Safety hazard'])\n",
        "  y.append(data[i]['Safety hazard'])\n",
        "  inner_list = [reviews]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6voKuUL2TWY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dd00134-188a-4272-f33e-81976c693646"
      },
      "source": [
        "#Create List of Unique Words\n",
        "unique_words = []\n",
        "print('Identifying unique words...')\n",
        "for line in reviews:\n",
        "  blob = TextBlob(line)\n",
        "  text = blob.words\n",
        "  for word in text:\n",
        "    if word not in unique_words:\n",
        "      unique_words.append(word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Identifying unique words...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UueH3bbxUtn4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c758006d-d221-4c41-f9d4-52099637a7e5"
      },
      "source": [
        "#create relevant words list\n",
        "relevant_words = []\n",
        "print('Generating relevance scores...')\n",
        "for word in unique_words:\n",
        "  a = 0\n",
        "  b = 0\n",
        "  c = 0\n",
        "  d = 0\n",
        "  for i in range(len(reviews)):\n",
        "    if word in reviews[i] and hazard[i] == 1:\n",
        "      a += 1\n",
        "    elif word in reviews[i] and hazard[i] == 0:\n",
        "      b += 1\n",
        "    elif word not in reviews[i] and hazard[i] == 1:\n",
        "      c += 1\n",
        "    elif word not in reviews[i] and hazard[i] == 0:\n",
        "      d += 1\n",
        "  if relevanceScore(a,b,c,d) > 4000:\n",
        "    relevant_words.append(word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating relevance scores...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8H88YfARDn6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b731a4b-6b4b-42e1-ad18-d771c6f1094d"
      },
      "source": [
        "#create the 2d list from 3rd pge of prompt\n",
        "print('Formatting 2D list...')\n",
        "for review in reviews:\n",
        "  temp_list =[]\n",
        "  for word in relevant_words:\n",
        "    if word in review:\n",
        "      temp_list.append(1)\n",
        "    else:\n",
        "      temp_list.append(0)\n",
        "  x.append(temp_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Formatting 2D list...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeHUPYUIYskC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b994b92f-29a3-4fec-bc88-545e4de8c968"
      },
      "source": [
        "#split data into training and testing data \n",
        "print('Training machine learning models...')\n",
        "#x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, train_size=0.8, test_size=0.2, random_state = 25)\n",
        "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x, y, test_size=0.33)\n",
        "# Decision tree\n",
        "dt_clf = sklearn.tree.DecisionTreeClassifier()\n",
        "dt_clf = dt_clf.fit(x_train, y_train)\n",
        "dt_predictions = dt_clf.predict(x_test)\n",
        "dt_accuracy = sklearn.metrics.accuracy_score(y_test, dt_predictions)\n",
        "print(\"DT accuracy:\", dt_accuracy)\n",
        "# KNN\n",
        "knn_clf = sklearn.neighbors.KNeighborsClassifier(5)\n",
        "knn_clf = knn_clf.fit(x_train, y_train)\n",
        "knn_predictions = knn_clf.predict(x_test)\n",
        "knn_accuracy = sklearn.metrics.accuracy_score(y_test, knn_predictions)\n",
        "print(\"KNN accuracy:\", knn_accuracy)\n",
        "\n",
        "# Neural network\n",
        "nn_clf = sklearn.neural_network.MLPClassifier()\n",
        "nn_clf = nn_clf.fit(x_train, y_train)\n",
        "nn_predictions = nn_clf.predict(x_test)\n",
        "nn_accuracy = sklearn.metrics.accuracy_score(y_test, nn_predictions)\n",
        "print(\"NN accuracy:\", nn_accuracy)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training machine learning models...\n",
            "DT accuracy: 0.8333333333333334\n",
            "KNN accuracy: 0.803030303030303\n",
            "NN accuracy: 0.8575757575757575\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "hQiE1dxD8B6j",
        "outputId": "795c5a0b-6ef7-43da-80cb-9b9784e933b2"
      },
      "source": [
        "#Find highest accuracy score and save joblib file\n",
        "acc_scores = [dt_accuracy, knn_accuracy, nn_accuracy]\n",
        "highest = max(acc_scores)\n",
        "if highest == acc_scores[0]:\n",
        "  print('Decision Tree model performed best; saved to model.joblib.')\n",
        "  joblib.dump(dt_clf, \"dt_model.joblib\")\n",
        "  google.colab.files.download(\"dt_model.joblib\")\n",
        "elif highest == acc_scores[1]:\n",
        "  print('K-Nearest Neighbors model performed best; saved to model.joblib.')\n",
        "  joblib.dump(knn_clf, \"knn_model.joblib\")\n",
        "  google.colab.files.download(\"knn_model.joblib\")\n",
        "elif highest == acc_scores[2]:\n",
        "  print('Neural network model performed best; saved to model.joblib.')\n",
        "  joblib.dump(nn_clf, \"nn_model.joblib\")\n",
        "  google.colab.files.download(\"nn_model.joblib\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Neural network model performed best; saved to model.joblib.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_11cddc55-7f15-48e6-9d26-2fa16407a6cd\", \"nn_model.joblib\", 110184)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}